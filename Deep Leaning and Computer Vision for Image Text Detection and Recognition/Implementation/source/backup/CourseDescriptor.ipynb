{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Automating Course Descriptor**\n",
        "\n",
        "# IT9502 Thesis\n",
        "\n",
        "**Student ID:** 22201670\n",
        "\n",
        "**Student Name:** Sachith M. Gunawardane"
      ],
      "metadata": {
        "id": "C67g1RYXBWVT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect to Google Drive\n",
        "\n",
        "*Google Drive holds training data for this research*\n",
        "* PDF files\n",
        "* PDF files created using images"
      ],
      "metadata": {
        "id": "K0OXrjKYCSxX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6vWF758BHXn",
        "outputId": "6aba98ca-a05f-4d4d-b2e1-3c6d5fc1dab6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "# Connect Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install External Packages\n",
        "\n",
        "* *PyPDF2* library has been chosen over *tika* because, tika is capable of reading PDF with specific page numbers. Therefore, if MsWord file required seperate implementation with and *docx* library."
      ],
      "metadata": {
        "id": "srOsxIbVDYFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install PyPDF2\n",
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6WzuT63DeoA",
        "outputId": "ad4bd0f2-17e0-4f66-875e-ad21cdf1240f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/232.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install MySQL connector\n",
        "!pip install mysql-connector-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leaYa9X0HZpZ",
        "outputId": "c66159cb-70b3-40a9-c318-0eb237114231"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mysql-connector-python\n",
            "  Downloading mysql_connector_python-8.2.0-cp310-cp310-manylinux_2_17_x86_64.whl (31.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.6/31.6 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf<=4.21.12,>=4.21.1 (from mysql-connector-python)\n",
            "  Downloading protobuf-4.21.12-cp37-abi3-manylinux2014_x86_64.whl (409 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.8/409.8 kB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf, mysql-connector-python\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.21.12 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed mysql-connector-python-8.2.0 protobuf-4.21.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "aZuQ-9EoDKwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import PyPDF2\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk import sent_tokenize\n",
        "from nltk import word_tokenize\n",
        "import re\n",
        "import mysql\n",
        "import mysql.connector as msql\n",
        "from mysql.connector import Error\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PivI3ytjDUmC",
        "outputId": "b50fac35-e32a-41f3-c6b1-cbd8956fe02b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Global Parameters"
      ],
      "metadata": {
        "id": "y28SgykCD4JW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Global Parameters\n",
        "## Ground Truth Parameter details\n",
        "ground_truth_file = '/content/gdrive/MyDrive/OWR/data/files/2023 Programme Handbook.pdf'\n",
        "start_page = 40\n",
        "end_page   = 130\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uiVt9H5kD9fd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# establish database connection\n",
        "try:\n",
        "  conn = msql.connect(host='db4free.net',database='education_nz' ,user='whitireia_admin',\n",
        "                        password='weltec#2023')\n",
        "except Error as e:\n",
        "    print(\"Error while connecting to MySQL now \", e)\n",
        "\n",
        "cursor = conn.cursor()"
      ],
      "metadata": {
        "id": "gkH0yiHOG8VA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementation\n",
        "\n",
        "*"
      ],
      "metadata": {
        "id": "yTfhuKttE4ZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_pageContent(pdf_reader, page_no):\n",
        "  ''' Function to read and extract text\n",
        "      Input:\n",
        "              1. pdf reader\n",
        "              2. Page number\n",
        "      Returns text from the requested page'''\n",
        "\n",
        "  page = pdf_reader.pages[int(page_no)]\n",
        "  text = page.extract_text().upper()\n",
        "\n",
        "  return text"
      ],
      "metadata": {
        "id": "eZ59gbnvE473"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_courseCode(text):\n",
        "  '''\n",
        "  This function is designed to extract Course Code\n",
        "  Input: Page text\n",
        "  Output: Course Code, Position for Level and Credit\n",
        "  Logic:  1. Track Level and Credit positions in List\n",
        "          2. Reverse search for\n",
        "                a. Text with length 6\n",
        "                b. Start with 2 characters\n",
        "                c. End with 2 numeric\n",
        "  '''\n",
        "\n",
        "  # extract words\n",
        "  words = word_tokenize(text)\n",
        "\n",
        "  # search string\n",
        "  search_str = ['Level','Credits']\n",
        "  word_gap = 3\n",
        "\n",
        "  # find the index of the search string\n",
        "  search_pos = []\n",
        "  for i, item in enumerate(words):\n",
        "    if item.lower() == search_str[0].lower():\n",
        "      search_pos.append(i)\n",
        "    if item.lower() == search_str[1].lower() and len(search_pos) > 0:\n",
        "      search_pos.append(i)\n",
        "\n",
        "    if len(search_pos) > 1:\n",
        "      if search_pos[1] - search_pos[0] < word_gap:\n",
        "        break\n",
        "      else: search_pos = []\n",
        "    elif len(search_pos) > 0 and (i - search_pos[0]) > word_gap:\n",
        "      search_pos = []\n",
        "\n",
        "  # regular expression patterns for code\n",
        "  pattern1 = r\"\\b\\w{6}\\b\" # word with 6 positions\n",
        "  pattern2 = r\"\\b^[a-zA-Z]{2}\\w+\" # start with 2 characters\n",
        "  pattern3 = r\"\\w+\\d{2}$\" # end with 2 numbers\n",
        "\n",
        "  code = None\n",
        "  if len(search_pos) > 0:\n",
        "    for i in range(search_pos[0], -1, -1):\n",
        "      matches1 = re.findall(pattern1, words[i])\n",
        "      matches2 = re.findall(pattern2, words[i])\n",
        "      matches3 = re.findall(pattern3, words[i])\n",
        "\n",
        "      if len(matches1)> 0 and len(matches2)> 0 and len(matches3)> 0:\n",
        "        code = words[i]\n",
        "        break\n",
        "\n",
        "  return (code, search_pos)"
      ],
      "metadata": {
        "id": "I2WTbKO6Y3NX"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_courseTitle(text, code, pos):\n",
        "  '''\n",
        "  This function is designed to return Course Tile\n",
        "  Prerequisite: get_courseCode\n",
        "  Input: Page text ,  Course Code and Position of Level and Credit\n",
        "  Output: Course Title\n",
        "  Logic: 1. Start position based on Course Code\n",
        "         2. End position based on Level\n",
        "  Both above information are retrieved from prerequisite function\n",
        "  '''\n",
        "\n",
        "  # extract words\n",
        "  words = word_tokenize(text)\n",
        "\n",
        "  Index_Code = words.index(code)\n",
        "\n",
        "  title = []\n",
        "  if Index_Code < pos[0]:\n",
        "    for i in range(Index_Code +1, pos[0]):\n",
        "      title.append(words[i])\n",
        "\n",
        "  if len(title) > 0:\n",
        "    return ' '.join(title, )\n",
        "  else: return None"
      ],
      "metadata": {
        "id": "-3_5J6j8W4qV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_courseLevel(text, pos):\n",
        "  '''\n",
        "  '''\n",
        "  #search text\n",
        "  end_search = 'Aim'\n",
        "  pattern = r\"\\b^\\d{1,2}\" # start with 2 numbers\n",
        "\n",
        "  # extract words\n",
        "  words = word_tokenize(text)\n",
        "\n",
        "  level = 0\n",
        "  for i in range(pos[0], len(words)):\n",
        "\n",
        "    matches = re.findall(pattern, words[i])\n",
        "\n",
        "    if len(matches) > 0:\n",
        "      try:\n",
        "        level = int(words[i])\n",
        "        break\n",
        "      except ValueError:\n",
        "        level = 0\n",
        "\n",
        "    if end_search.lower() == words[i].lower():\n",
        "      break\n",
        "\n",
        "  return level"
      ],
      "metadata": {
        "id": "-G1Wfx2RQcgM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_courseCredit(text, pos):\n",
        "  #search text\n",
        "  end_search = 'Aim'\n",
        "  pattern = r\"\\b^\\d{1,2}\" # start with 2 numbers\n",
        "\n",
        "  # extract words\n",
        "  words = word_tokenize(text)\n",
        "\n",
        "  credit = 0\n",
        "  for i in range(pos[1], len(words)):\n",
        "\n",
        "    matches = re.findall(pattern, words[i])\n",
        "\n",
        "    if len(matches) > 0:\n",
        "      try:\n",
        "        credit = int(words[i])\n",
        "        break\n",
        "      except ValueError:\n",
        "        credit = 0\n",
        "\n",
        "    if end_search.lower() == words[i].lower():\n",
        "      break\n",
        "  return credit"
      ],
      "metadata": {
        "id": "1TPMpH7s1vNx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_courseTutorHrs(text):\n",
        "\n",
        "  # search text\n",
        "  search_text = ('learning', 'tutor','tutor-directed')\n",
        "  stop_text   = ('aim','aims')\n",
        "  pattern = r\"\\b^\\d{1,2}\" # start with 2 numbers\n",
        "\n",
        "  # extract words\n",
        "  words = word_tokenize(text)\n",
        "\n",
        "  search_pos = []\n",
        "  for i, item in enumerate(words):\n",
        "    if item.lower() in search_text:\n",
        "      search_pos.append(i)\n",
        "\n",
        "    if item.lower() in stop_text:\n",
        "      break\n",
        "\n",
        "  tutor_hrs = 0\n",
        "  if len(search_pos) > 0:\n",
        "    search_pos.sort(reverse=True)\n",
        "\n",
        "    for i in range(search_pos[0], len(words)):\n",
        "      matches = re.findall(pattern, words[i])\n",
        "\n",
        "      if len(matches) > 0:\n",
        "        try:\n",
        "          tutor_hrs = int(words[i])\n",
        "          break\n",
        "        except ValueError:\n",
        "          tutor_hrs = 0\n",
        "\n",
        "      if words[i].lower() ==  stop_text:\n",
        "        break\n",
        "\n",
        "  return tutor_hrs"
      ],
      "metadata": {
        "id": "7CnlC4Jj3KGM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_courseSelfHrs(text):\n",
        "\n",
        "  # search text\n",
        "  search_text = ('learning', 'self','self-directed')\n",
        "  stop_text   = ('aim','aims')\n",
        "  pattern = r\"\\b^\\d{1,2}\" # start with 2 numbers\n",
        "\n",
        "  # extract words\n",
        "  words = word_tokenize(text)\n",
        "\n",
        "  search_pos = []\n",
        "  for i, item in enumerate(words):\n",
        "    if item.lower() in search_text:\n",
        "      search_pos.append(i)\n",
        "\n",
        "    if item.lower() in stop_text:\n",
        "      break\n",
        "\n",
        "  self_hrs = 0\n",
        "  if len(search_pos) > 0:\n",
        "    search_pos.sort(reverse=True)\n",
        "\n",
        "    for i in range(search_pos[0], len(words)):\n",
        "      matches = re.findall(pattern, words[i])\n",
        "\n",
        "      if len(matches) > 0:\n",
        "        try:\n",
        "          self_hrs = int(words[i])\n",
        "          break\n",
        "        except ValueError:\n",
        "          self_hrs = 0\n",
        "\n",
        "      if words[i].lower() ==  stop_text:\n",
        "        break\n",
        "\n",
        "    if self_hrs == 0:\n",
        "      for i in range(search_pos[0]-1, len(words)):\n",
        "        matches = re.findall(pattern, words[i])\n",
        "\n",
        "        if len(matches) > 0:\n",
        "          try:\n",
        "            self_hrs = int(words[i])\n",
        "            break\n",
        "          except ValueError:\n",
        "            self_hrs = 0\n",
        "\n",
        "        if words[i].lower() ==  stop_text:\n",
        "          break\n",
        "\n",
        "  return self_hrs"
      ],
      "metadata": {
        "id": "YcY4StHM5FcL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_endPoint4Exceptions(sentence):\n",
        "  end_text_exception = ['learning outco mes','lear ning outcomes',\n",
        "                        'identify and explain contemporary','critically analyse ethical issues'\n",
        "                       ]\n",
        "\n",
        "  count = 0\n",
        "  positions = []\n",
        "  for search_word in end_text_exception:\n",
        "    pos = sentence.lower().find(search_word)\n",
        "    if pos != -1:\n",
        "      count += 1\n",
        "      positions.append(pos)\n",
        "\n",
        "    if count > 0:\n",
        "      break\n",
        "\n",
        "  if count > 0:\n",
        "    return positions[0]\n",
        "  else: return len(sentence)\n",
        "\n",
        "def get_courseAim(text):\n",
        "\n",
        "  # search text\n",
        "  search_text  = 'aim'\n",
        "  end_text = 'learning outcomes'\n",
        "\n",
        "  # extract sentence\n",
        "  sentences = sent_tokenize(text)\n",
        "\n",
        "  # get 1st sentence with 'aim' word\n",
        "  aim = ''\n",
        "  pos = -1\n",
        "  end_pos = -1\n",
        "  start_flag = False\n",
        "  stop_flag = False\n",
        "  for sentance in sentences:\n",
        "    if not start_flag:\n",
        "      pos = sentance.lower().find(search_text)\n",
        "      if pos != -1:\n",
        "        start_flag = True\n",
        "        temp_pos = sentance[pos:].find('\\n')\n",
        "        if temp_pos != -1 and temp_pos < 6:\n",
        "          pos += temp_pos\n",
        "\n",
        "    if start_flag:\n",
        "      temp_pos = sentance.lower().find(end_text)\n",
        "      if temp_pos != -1:\n",
        "        end_pos = temp_pos\n",
        "        stop_flag = True\n",
        "      else:\n",
        "        end_pos = get_endPoint4Exceptions(sentance)\n",
        "        if end_pos != len(sentance):\n",
        "          stop_flag = True\n",
        "\n",
        "      aim += sentance[pos:end_pos] + '\\n'\n",
        "\n",
        "      pos = 0\n",
        "      if stop_flag:\n",
        "        break\n",
        "\n",
        "  aim = aim.lstrip(\"\\n\")\n",
        "  aim = aim.rstrip(\"\\n\")\n",
        "\n",
        "  return aim"
      ],
      "metadata": {
        "id": "GNToWVmGDcRD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_coursePrerequisite(text, course_credit, tutor_directed):\n",
        "\n",
        "  ignore_text = ('learning', 'hours', 'tutor','tutor-directed','directed','-directed',\n",
        "                 'pre-requisites', '-requisites','requisites' ,'none',str(tutor_directed))\n",
        "  stop_text = ('pre-requisites', '-requisites','requisites', str(course_credit), 'credits' )\n",
        "\n",
        "  # regular expression patterns for code\n",
        "  pattern1 = r\"\\b\\w{6}\\b\" # word with 6 positions\n",
        "  pattern2 = r\"\\b^[a-zA-Z]{2}\\w+\" # start with 2 characters\n",
        "  pattern3 = r\"\\w+\\d{2}$\" # end with 2 numbers\n",
        "\n",
        "  # extract words\n",
        "  words = word_tokenize(text)\n",
        "\n",
        "  start_pos = 0\n",
        "  for i, item in enumerate(words):\n",
        "    if item.lower() == str(tutor_directed):\n",
        "      start_pos = i\n",
        "      break\n",
        "\n",
        "  code = []\n",
        "  title = []\n",
        "  code_flag = False\n",
        "  output = []\n",
        "  for i in range(i,0,-1):\n",
        "\n",
        "    if words[i].lower() in stop_text:\n",
        "      break\n",
        "\n",
        "    if not ( words[i].lower() in ignore_text):\n",
        "      match_num = re.findall(pattern3, words[i])\n",
        "      if len(match_num) > 0:\n",
        "        code.append(words[i])\n",
        "      elif code_flag:  code.append(words[i])\n",
        "      else: title.append(words[i])\n",
        "\n",
        "    if len(code) > 0:\n",
        "      tempCode = code.copy()\n",
        "      tempCode.reverse()\n",
        "      course_code = ''.join(tempCode)\n",
        "\n",
        "      if len(course_code) < 6:\n",
        "        code_flag = True\n",
        "\n",
        "      matches1 = re.findall(pattern1, course_code)\n",
        "      matches2 = re.findall(pattern2, course_code)\n",
        "      matches3 = re.findall(pattern3, course_code)\n",
        "\n",
        "      if len(matches1)> 0 and len(matches2)> 0 and len(matches3)> 0:\n",
        "        tempTitle = title.copy()\n",
        "        tempTitle.reverse()\n",
        "        output.append([course_code, ' '.join(tempTitle)])\n",
        "        code = []\n",
        "        title = []\n",
        "        code_flag = False\n",
        "\n",
        "\n",
        "  return output"
      ],
      "metadata": {
        "id": "cjGWp2_WbVX3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_courseLearningOutcome(text):\n",
        "\n",
        "  # search text\n",
        "  search_text = ('learning', 'outcomes','outco', 'mes','lear' ,'ning')\n",
        "  stop_text   = ('indicative', 'content', 'conte', 'nt', '•')\n",
        "\n",
        "  # regular expression patterns for code\n",
        "  pattern = r\"\\d{1}$\" # end with 1 numbers\n",
        "\n",
        "  # extract words\n",
        "  words = word_tokenize(text)\n",
        "\n",
        "  start_pos = []\n",
        "  end_pos = []\n",
        "  for i, item in enumerate(words):\n",
        "    if item.lower() in search_text and words[i+1].lower() in search_text:\n",
        "      start_pos.append(i+1)\n",
        "      break\n",
        "\n",
        "  for i, item in enumerate(words):\n",
        "    if item.lower() in stop_text:\n",
        "      end_pos.append(i)\n",
        "      break\n",
        "\n",
        "\n",
        "  learning_outcome = []\n",
        "  index = -1\n",
        "  outcome = []\n",
        "  start_flag = False\n",
        "  for i in range(start_pos[0], end_pos[0]):\n",
        "    if (len(words[i]) == 1) and (len(re.findall(pattern, words[i])) > 0):\n",
        "      if index != -1:\n",
        "        learning_outcome.append([index, ' '.join(outcome)])\n",
        "        outcome = []\n",
        "      index = int( words[i])\n",
        "      start_flag = True\n",
        "      continue\n",
        "    elif start_flag:\n",
        "      if not ((len(words[i-1]) == 1) and (len(re.findall(pattern, words[i-1])) > 0) and words[i] == '.') :\n",
        "        outcome.append(words[i])\n",
        "  if index != -1:\n",
        "    learning_outcome.append([index, ' '.join(outcome)])\n",
        "\n",
        "  return learning_outcome"
      ],
      "metadata": {
        "id": "ogURmgYC8l6L"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string1 = '3-5'\n",
        "string2 = '-'\n",
        "\n",
        "if string2 in string1:\n",
        "  string3 = string1.split(string2)\n",
        "  for i in range(int(string3[0]), int(string3[1]) +1 ):\n",
        "    print(i)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CO8fwA9ENRSY",
        "outputId": "1caf8ddc-7c33-4cf4-c2cb-8cc399f6ee3a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "4\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_courseCompletion(text):\n",
        "\n",
        "  output = []\n",
        "  specialChar = '•'\n",
        "\n",
        "  # search text\n",
        "  text_array = text.splitlines()\n",
        "\n",
        "  search_text = ('ASSESSMENTS' , 'ASSESSMENT',  'METHOD',  'WEIGHTING',  'LEARNING',  'OUTCOME/S')\n",
        "  search_text2 = ('SUCCESSFUL', 'COMPLETION', 'OF', 'COURSE')\n",
        "  end_text = ('RESOURCES')\n",
        "\n",
        "  start_pos = []\n",
        "  mid_pos = []\n",
        "  end_pos = []\n",
        "\n",
        "  for i, item in enumerate(text_array):\n",
        "\n",
        "    words = word_tokenize(item)\n",
        "    for word in words:\n",
        "      if word.upper() in search_text:\n",
        "        if max(start_pos, default = 0) + 3 > i:\n",
        "          start_pos.append(i)\n",
        "        else:\n",
        "          start_pos.clear()\n",
        "          start_pos.append(i)\n",
        "\n",
        "      if word.upper() in search_text2:\n",
        "        if not(len(mid_pos) > 3):\n",
        "          if max(mid_pos, default = 0) + 2 > i and len(start_pos) > 2:\n",
        "            mid_pos.append(i)\n",
        "          else:\n",
        "            mid_pos.clear()\n",
        "            mid_pos.append(i)\n",
        "\n",
        "      if word.upper() in end_text:\n",
        "        if len(mid_pos) > 2:\n",
        "          end_pos.append(i)\n",
        "\n",
        "\n",
        "      if len(mid_pos) > 3 and len(end_pos) > 0 :\n",
        "        break\n",
        "    if len(mid_pos) > 3 and len(end_pos) > 0:\n",
        "      break\n",
        "\n",
        "  if len(end_pos) == 0:\n",
        "    end_pos.append(len(text_array))\n",
        "\n",
        "  assess_start = max(mid_pos, default = 0) + 1\n",
        "  assess_end = max(end_pos, default = 0)\n",
        "\n",
        "  print(assess_start)\n",
        "  print(assess_end)\n",
        "  outtext = []\n",
        "  for sentance in text_array[assess_start:assess_end]:\n",
        "    words = word_tokenize(sentance)\n",
        "    for i in range(len(words)):\n",
        "      if specialChar in words[i] and  i == 0 and len(outtext) > 0:\n",
        "        output.append(' '.join(outtext))\n",
        "        outtext.clear()\n",
        "      else :\n",
        "        tmpStr = words[i]\n",
        "        tmpStr = tmpStr.strip()\n",
        "        if len(tmpStr) > 0:outtext.append(tmpStr)\n",
        "  output.append(' '.join(outtext))\n",
        "\n",
        "  return output"
      ],
      "metadata": {
        "id": "D6zBZtNAo3aO"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_courseAssessments(text):\n",
        "\n",
        "  method = []\n",
        "  weight = []\n",
        "  learning = []\n",
        "\n",
        "  SpecialChar = '-'\n",
        "\n",
        "  # search text\n",
        "\n",
        "  text_array = text.splitlines()\n",
        "\n",
        "  search_text = ('ASSESSMENTS' , 'ASSESSMENT',  'METHOD',  'WEIGHTING',  'LEARNING',  'OUTCOME/S')\n",
        "  end_text = ('SUCCESSFUL', 'COMPLETION', 'OF', 'COURSE')\n",
        "\n",
        "  start_pos = []\n",
        "  end_pos = []\n",
        "\n",
        "  for i, item in enumerate(text_array):\n",
        "\n",
        "    words = word_tokenize(item)\n",
        "    for word in words:\n",
        "      if word.upper() in search_text:\n",
        "        if max(start_pos, default = 0) + 3 > i:\n",
        "          start_pos.append(i)\n",
        "        else:\n",
        "          start_pos.clear()\n",
        "          start_pos.append(i)\n",
        "\n",
        "      if word.upper() in end_text:\n",
        "        if max(end_pos, default = 0) + 2 > i and len(start_pos) > 2:\n",
        "          end_pos.append(i)\n",
        "        else:\n",
        "          end_pos.clear()\n",
        "          end_pos.append(i)\n",
        "\n",
        "      if len(end_pos) > 3:\n",
        "        break\n",
        "    if len(end_pos) > 3:\n",
        "      break\n",
        "\n",
        "  assess_start = max(start_pos, default = 0) + 1\n",
        "  assess_end = max(end_pos, default = 0)\n",
        "\n",
        "  for i in range(assess_start, assess_end):\n",
        "    words = word_tokenize(text_array[i])\n",
        "    try:\n",
        "      percentagePos =  words.index('%')\n",
        "    except:\n",
        "      continue\n",
        "\n",
        "    method.append(''.join(words[:percentagePos - 1]))\n",
        "    weight.append(words[percentagePos -1])\n",
        "\n",
        "    learningOutcome = []\n",
        "    for word in words[percentagePos +1:]:\n",
        "      if word.upper() == 'ALL':\n",
        "        learningOutcome.append('99')\n",
        "      elif SpecialChar in word:\n",
        "        tmpWord = word.split(SpecialChar)\n",
        "        for i in range(int(tmpWord[0]), int(tmpWord[1]) +1 ):\n",
        "          learningOutcome.append(str(i))\n",
        "      elif word.isdigit():\n",
        "        learningOutcome.append(word)\n",
        "    learning.append(learningOutcome)\n",
        "\n",
        "\n",
        "  return   method, weight, learning\n",
        ""
      ],
      "metadata": {
        "id": "JmEV9XjiVLVn"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementation of DB Functionality"
      ],
      "metadata": {
        "id": "39SAWoAIIeNt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_version(cur, name, des):\n",
        "\n",
        "  # Get the current date and time\n",
        "  now = datetime.now()\n",
        "\n",
        "  # Format the current date and time as a string in MySQL datetime format\n",
        "  dt_string = now.strftime('%Y-%m-%d %H:%M:%S')\n",
        "\n",
        "  insert_query = 'INSERT INTO education_nz.version (name, description, created_datetime) VALUES (%s, %s, %s)'\n",
        "  values =(name, des, dt_string )\n",
        "\n",
        "  cur.execute(insert_query, values)\n",
        "  cur.commit()\n",
        "\n",
        "\n",
        "\n",
        "  return None"
      ],
      "metadata": {
        "id": "0miK7wAQJ0Ue"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_course(course_details, cur):\n",
        "\n",
        "  return None"
      ],
      "metadata": {
        "id": "dr-b70QwIluX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ground Truth Creation"
      ],
      "metadata": {
        "id": "ZLvAUrXCSVlb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of pages to be read\n",
        "no_of_pages = np.arange(start_page, end_page+ 1, dtype=int)\n",
        "\n",
        "# Open Ground Truth File\n",
        "gt_pdf_file = open(ground_truth_file, 'rb')\n",
        "\n",
        "# Create a PDF reader object\n",
        "gt_pdf_reader = PyPDF2.PdfReader(gt_pdf_file)\n"
      ],
      "metadata": {
        "id": "NA0KghTUSNzF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#no_of_pages= [45,46,66,67,68,71,72]\n",
        "#for page in no_of_pages:\n",
        "if True:\n",
        "  page = 65\n",
        "  # get the text of given page\n",
        "  passed_page = get_pageContent(gt_pdf_reader,page)\n",
        "  print(passed_page)\n",
        "\n",
        "  # get course code\n",
        "  course_code, level_credit_pos = get_courseCode(passed_page)\n",
        "  print(course_code)\n",
        "\n",
        "  # if course code extracted successful proceed\n",
        "  if course_code != None:\n",
        "    # get course title\n",
        "    course_title = get_courseTitle(passed_page, course_code, level_credit_pos)\n",
        "    print(course_title)\n",
        "\n",
        "    # get course level\n",
        "    course_level = get_courseLevel(passed_page,level_credit_pos)\n",
        "    print(course_level)\n",
        "\n",
        "    # get course credit\n",
        "    course_credit = get_courseCredit(passed_page,level_credit_pos)\n",
        "    print(course_credit)\n",
        "\n",
        "    # get tutor directed\n",
        "    course_tutor_directed = get_courseTutorHrs(passed_page)\n",
        "    print(course_tutor_directed)\n",
        "\n",
        "    # get self directed\n",
        "    course_self_directed = get_courseSelfHrs(passed_page)\n",
        "\n",
        "    # get aim\n",
        "    course_aim = get_courseAim(passed_page)\n",
        "\n",
        "    # get course pre-requisite\n",
        "    course_prerequisite = get_coursePrerequisite(passed_page, course_credit, course_tutor_directed)\n",
        "    print(course_prerequisite)\n",
        "\n",
        "    # get Learning outcome\n",
        "    course_learning_outcomes = get_courseLearningOutcome(passed_page)\n",
        "    print(course_learning_outcomes)\n",
        "\n",
        "    # get Assessments\n",
        "    print(get_courseAssessments(passed_page))\n",
        "\n",
        "    print(get_courseCompletion(passed_page))\n",
        "\n",
        "\n",
        "    #print('Credit', get_courseCredit(passed_page,level_credit_pos))\n",
        "\n",
        "    ## DB functinality\n",
        "    #DB_versionID =\n",
        "\n",
        "    # DB_courseID = insert_course([course_code,\n",
        "    #                              course_title,\n",
        "    #                              course_credit,\n",
        "    #                              course_level,\n",
        "    #                              course_tutor_directed,\n",
        "    #                              course_self_directed,\n",
        "\n",
        "\n",
        "    # ], cursor)\n",
        "    # print(DB_courseID)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#print('*'*15 ,'Start Doc','*'*15 )\n",
        "#print(passed_page)\n",
        "\n",
        "#print('*'*15 ,'Start Words','*'*15 )\n",
        "#words = word_tokenize(passed_page)\n",
        "#print(words)\n",
        "\n",
        "#print('*'*15 ,'Start Sentences','*'*15 )\n",
        "#sentences = sent_tokenize(passed_page)\n",
        "#print(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3z-l0gf0Mlbm",
        "outputId": "fbeed584-084a-4316-89e4-3d75019db012"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW ZEALAND CERTIFICATE IN INFORMATION TECHNOLOGY ESSENTIALS (LEVEL 4)  – PROGRAMME DOCUMENT  66 CS6503  DIGITAL FORENSICS  \n",
            "LEVEL  6 CREDITS  15 \n",
            "PRE-REQUISITES  IT5504 INFORMATION SECURITY I  \n",
            " IT5506 INTRODUCTION TO NETWORKING  \n",
            "LEARNING HOURS  TUTOR DIRECTED    52 HOURS   \n",
            " SELF-DIRECTED    98 HOURS  \n",
            "AIM \n",
            "TO PROVIDE LEARNERS WITH A COMPREHENSIVE UNDERSTANDING OF DIGITAL FORENSIC PRINCIPLES AND THE COLLECTION, \n",
            "PRESERVATION, AND ANALYSIS OF DIGITAL EVIDENCE.  \n",
            " \n",
            "LEARNING OUTCOMES  \n",
            "ON SUCCESSFUL COMPLETION OF THIS COURSE, THE LEARNER WILL BE ABLE TO:  \n",
            "1. IDENTIFY THE  ATTRIBUTES OF FILE SYSTEMS AND STORAGE MEDIA AND PERFORM ANALYSIS ON AT LEAST TWO COMMON \n",
            "FILE SYSTEMS  \n",
            "2. IDENTIFY AND ANALYSE POTENTIAL SOURCES OF ELECTRONIC EVIDENCE  \n",
            "3. DESCRIBE THE IMPORTANCE OF MAINTAINING THE INTEGRITY OF DIGITAL EVIDENCE  \n",
            "4. PERFORM BASIC FORE NSIC DATA ACQUISITION AND ANALYSIS USING COMPUTER AND NETWORK -BASED APPLICATIONS \n",
            "AND UTILITIES  \n",
            "5. ACCURATELY DOCUMENT FORENSIC PROCEDURES AND RESULTS AND DEVELOP A CASE SUMMARY  \n",
            "INDICATIVE CONTENT  \n",
            "• FORENSIC INVESTIGATION  \n",
            "• OPERATING SYSTEM FUNCTIONALITY  \n",
            "• FILE SY STEM ANALYSIS  \n",
            "• OPERATING SYSTEM ARTIFACT ANALYSIS  \n",
            "• BROWSER AND EMAIL ANALYSIS  \n",
            "• INVESTIGATIVE METHODOLOGIES  \n",
            "• FORENSIC REPORT WRITING  \n",
            "• OVERVIEW OF MEMORY FORENSICS  \n",
            "ASSESSMENTS  \n",
            "ASSESSMENT METHOD  WEIGHTING  LEARNING OUTCOME/S  \n",
            "ASSIGNMENT 1  30%  1, 2, 4  \n",
            "ASSIGNMENT 2  30%  2, 3, 5  \n",
            "EXAMINATION  40%  1-5 \n",
            " \n",
            "SUCCESSFUL COMPLETION OF COURSE  \n",
            "TO PASS A COURSE WHERE THERE IS AN EXAMINATION SET, A LEARNER MUST:  \n",
            "• ATTEMPT ALL ASSESSMENTS  \n",
            "• ACHIEVE AN AVERAGE MARK OF 50%  OR ABOVE OVER ALL ASSESSMENTS, INCLUDING THE EXAMINATION  \n",
            "• ACHIEVE A MARK OF 40%  OR ABOVE IN THEIR FINAL EXAMINATION  \n",
            " \n",
            "  \n",
            "CS6503\n",
            "DIGITAL FORENSICS\n",
            "6\n",
            "15\n",
            "52\n",
            "[['IT5506', 'INTRODUCTION TO NETWORKING'], ['IT5504', 'INFORMATION SECURITY I']]\n",
            "[[1, 'IDENTIFY THE ATTRIBUTES OF FILE SYSTEMS AND STORAGE MEDIA AND PERFORM ANALYSIS ON AT LEAST TWO COMMON FILE SYSTEMS'], [2, 'IDENTIFY AND ANALYSE POTENTIAL SOURCES OF ELECTRONIC EVIDENCE'], [3, 'DESCRIBE THE IMPORTANCE OF MAINTAINING THE INTEGRITY OF DIGITAL EVIDENCE'], [4, 'PERFORM BASIC FORE NSIC DATA ACQUISITION AND ANALYSIS USING COMPUTER AND NETWORK -BASED APPLICATIONS AND UTILITIES'], [5, 'ACCURATELY DOCUMENT FORENSIC PROCEDURES AND RESULTS AND DEVELOP A CASE SUMMARY']]\n",
            "(['ASSIGNMENT1', 'ASSIGNMENT2', 'EXAMINATION'], ['30', '30', '40'], [['1', '2', '4'], ['2', '3', '5'], ['1', '2', '3', '4', '5']])\n",
            "35\n",
            "41\n",
            "['TO PASS A COURSE WHERE THERE IS AN EXAMINATION SET , A LEARNER MUST :', 'ATTEMPT ALL ASSESSMENTS', 'ACHIEVE AN AVERAGE MARK OF 50 % OR ABOVE OVER ALL ASSESSMENTS , INCLUDING THE EXAMINATION', 'ACHIEVE A MARK OF 40 % OR ABOVE IN THEIR FINAL EXAMINATION']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  page = 67\n",
        "  # get the text of given page\n",
        "  passed_page = get_pageContent(gt_pdf_reader,page)\n",
        "  print(passed_page)\n",
        "\n",
        "  print(get_courseCompletion(passed_page))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JunLICNlDEyE",
        "outputId": "a2608b41-0457-4f4c-a371-39f92a7169dc"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW ZEALAND CERTIFICATE IN INFORMATION TECHNOLOGY ESSENTIALS (LEVEL 4)  – PROGRAMME DOCUMENT  68 DS6501  SOCIAL DATA ANALYTICS  \n",
            " \n",
            "LEVEL 6  CREDITS 15  \n",
            "PRE-REQUISITES  IT5507 FUNDAMENTALS OF DATA SCIENCE  \n",
            "LEARNING HOURS  TUTOR DIRECTED    52 HOURS  \n",
            " SELF-DIRECTED    98 HOURS  \n",
            "AIM \n",
            "TO INTRODUCE LEARNERS TO THE ANALYSIS OF SOCIAL DATA USING TOOLS AND TECHNIQUES TO EXTRACT KNOWLEDGE AND INSIGHTS FROM \n",
            "SOCIAL MEDIA NETWORKS.  \n",
            "LEARNING OUTCO MES  \n",
            "ON SUCCESSFUL COMPLETION OF THIS COURSE, THE LEARNER WILL BE ABLE TO:  \n",
            "1. IDENTIFY AND EXPLAIN CONTEMPORARY TEXT MINING TASKS TYPICALLY APPLIED TO DOCUMENT COLLECTIONS  \n",
            "2. PERFORM INTRODUCTORY TEXT MINING TASKS ON PUBLICLY  AVAILABLE SOCIAL MEDIA DATA  \n",
            "3. IDENTIFY AND EXPLAIN THE VISUAL ANALYTICAL CONCEPTS APPLIED TO LARGE SOCIAL DATA SETS  \n",
            "4. ANALYSE AND DISCUSS CURRENT SOCIAL, ETHICAL, SECURITY AND PRIVACY ISSUES RELATING TO LARGE -SCALE SOCIAL DATA \n",
            "ANALYTICS  \n",
            "INDICATIVE CONTENT  \n",
            "• SOCIAL DATA ANALYTICS AND THE FACTORS OF CONTEXT, CONTENT AND SENTIMENT  \n",
            "• MACHINE LEARNING TECHNIQUES EMPLOYED TO MODEL AND STRUCTURE THE INFORMATION CONTENT OF TEXTUAL DATA  \n",
            "• TEXT ANALYTICS TECHNIQUES USED IN SENTIMENT ANALYSIS TO DETERMINE PEOPLE’S ATTITUDES  \n",
            "• DATA MINING TECHNIQUES SUCH AS LINK AND ASSOCIATION ANALYSIS, VISUALISATION AND PREDICTIVE ANALYTICS USING \n",
            "STATISTICAL PROGRAMMING TOOLS  \n",
            "• API’S FOR ACCESSING DATA ON SOCIAL NETWORKS  \n",
            "• CONTEMPORARY ISSUES RELATING TO SOCIAL MEDIA DATA  \n",
            "ASSESSMENTS  \n",
            " \n",
            "ASSESSMENT M ETHOD  WEIGHTING  LEARNING OUTCOME/S  \n",
            "COURSE WORK  60%  1, 2 \n",
            "TEST  40%  1, 3, 4  \n",
            "SUCCESSFUL COMPLETION OF COURSE  \n",
            "TO PASS A COURSE WHERE THERE IS NO FINAL EXAMINATION, A LEARNER MUST:  \n",
            "• ATTEMPT ALL ASSESSMENTS  \n",
            "• ACHIEVE AN AVERAGE MARK OF 50%  OR ABOVE OVER ALL ASSESSMENTS  \n",
            "  \n",
            "30\n",
            "34\n",
            "['TO PASS A COURSE WHERE THERE IS NO FINAL EXAMINATION , A LEARNER MUST :', 'ATTEMPT ALL ASSESSMENTS', 'ACHIEVE AN AVERAGE MARK OF 50 % OR ABOVE OVER ALL ASSESSMENTS']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  page = 40\n",
        "  # get the text of given page\n",
        "  passed_page = get_pageContent(gt_pdf_reader,page)\n",
        "  print(passed_page)\n",
        "  print(get_courseCompletion(passed_page))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNEOHrDGK0rz",
        "outputId": "0607f93b-8e4f-4066-c7a4-1fdfccee3bc5"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NEW ZEALAND CERTIFICATE IN INFORMATION TECHNOLOGY ESSENTIALS (LEVEL 4)  – PROGRAMME DOCUMENT  41 IT5116  DATABASE ADMINISTRATION  \n",
            " \n",
            "LEVEL  5  CREDITS  15 \n",
            "LEARNING HOURS  TUTOR -DIRECTED   85   \n",
            " SELF-DIRECTED   65 \n",
            "AIM \n",
            "THIS COURSE INTRODUCES STUDENTS TO KEY DATABASE CONCEPTS AS WELL AS DEVELOPING SKILLS TO MANAGE AND ADMINISTRATE A \n",
            "RELATIONAL DATABASE.  \n",
            "LEARNING OUTCOMES  \n",
            "BY THE END OF THIS COURSE THE STUDENT WILL BE ABLE TO:  \n",
            "1. DESCRIBE  AND APPLY  DATABASE ADMINISTRATION AND QUERY LANGUAGES (SQL) TO MEET ORGANISATIONAL DATA STORAGE \n",
            "AND RETRIEVAL REQUIREMENTS, INCLUDING DATABASE MANAGEMENT (DBMS) OPTIMISATION, CLEANSING, SECURITY, AND \n",
            "BACKUPS.  \n",
            "2. IMPLEMENT THE FUNDAMENTAL  KNOWLEDGE OF DATA MODELLING.  \n",
            "3. APPLY FUNDAMENTAL MATHEMATICAL AND LOGICAL CONCEPTS FOR A RELATIONAL DATABASE.  \n",
            "4. APPLY P ROBLEM -SOLVING TECHNIQUES TO DATABASE RELATED ISSUES.  \n",
            "CONTENT  \n",
            "• RELATIONAL DATABASE CONCEPTS  \n",
            "• DATABASE MANAGEMENT SYSTEM (DBMS)  \n",
            "• BASIC SQL COMMA NDS \n",
            "• RELATIONAL DATABASE ADMINISTRATION  \n",
            "• RELATIONAL ALGEBRA  \n",
            "ASSESSMENTS  \n",
            "ASSESSMENT METHOD  WEIGHTING  LEARNING OUTCOME/S  \n",
            "PRACTICAL ASSESSMENT  60 %  1, 2, 4  \n",
            "PRACTICAL TEST   10 %  1  \n",
            "WRITTEN TEST  30 %  1 - 4 \n",
            "SUCCESSFUL COMPLETION OF COURSE  \n",
            "STUDENTS MUST GAIN 50 % OR MORE OF THE TOTAL AVAILABLE MARKS FROM THE COURSE WORK AND HAVE MADE A GENUINE \n",
            "ATTEMPT OF ALL ASSESSMENTS.  \n",
            "RESOURCES  \n",
            "A LIST OF RECOMMENDED RESOURCES IS PROVIDED IN THE COURSE OUTLINE.  \n",
            " \n",
            " \n",
            "  \n",
            "28\n",
            "30\n",
            "['STUDENTS MUST GAIN 50 % OR MORE OF THE TOTAL AVAILABLE MARKS FROM THE COURSE WORK AND HAVE MADE A GENUINE ATTEMPT OF ALL ASSESSMENTS .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "method, weight, learning = get_courseAssessments(passed_page)\n",
        "\n",
        "print(method)\n",
        "print(weight)\n",
        "print(learning)\n",
        "\n",
        "# print(type(passed_page))\n",
        "# print(len(passed_page))\n",
        "\n",
        "# string_array = passed_page.splitlines()\n",
        "\n",
        "# print(string_array)\n",
        "# print(len(string_array))\n",
        "# index = 0\n",
        "# for word in string_array:\n",
        "#   index += 1\n",
        "#   print(index ,word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqM0pyEED0vT",
        "outputId": "65ff267d-e433-4f8b-94e1-8206b0c8caa2"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ASSIGNMENT1', 'ASSIGNMENT2', 'EXAMINATION']\n",
            "['30', '30', '40']\n",
            "[['1', '2', '4'], ['2', '3', '5'], ['1', '2', '3', '4', '5']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Close the PDF file\n",
        "gt_pdf_file.close()\n",
        "\n",
        "# Disconnect from MySQL database\n",
        "conn.close()"
      ],
      "metadata": {
        "id": "m0vBiIfpVjqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "string = 'New Zealand Certificate in Information Technology Essentials (Level 4)  – Programme Document  44 IT5119  IT Technical Support'\n",
        "#string = '44'\n",
        "pattern = r\"\\b\\w{6}\\b\"\n",
        "\n",
        "matches = re.findall(pattern, string)\n",
        "\n",
        "print(matches)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ihr46uSyHoaA",
        "outputId": "fd23a9e9-59d2-44ae-caf4-eafbecd111be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['IT5119']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string = \"IT519\"\n",
        "#pattern = r\"\\b\\w{6}\\b\"\n",
        "#pattern = r\"\\b^[a-zA-Z]{2}\\w+\"\n",
        "pattern = r\"\\w+\\d{4}$\"\n",
        "matches = re.findall(pattern, string)\n",
        "\n",
        "print(matches)  # Output: ['1234']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHQ5ZzdR8HmY",
        "outputId": "c0663e7f-4ffa-48dc-faaa-f847765abf46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string = \"1234 is a valid code, XY7890 too, 1A2345 and ABCD are not 1 23\"\n",
        "pattern = r\"\\b^\\d{1,2}\"\n",
        "matches = re.findall(pattern, string)\n",
        "\n",
        "print(matches)  # Output: ['AB1234', 'XY7890']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dm315_X_Xf6",
        "outputId": "1e5382f2-9ac5-4275-e7cd-de4c994da2d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['12']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10,-1,-1):\n",
        "  if i > 5: continue\n",
        "  print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxKLTa1HK4xU",
        "outputId": "3cf605dd-c386-4fb0-def8-db226e86b27c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "4\n",
            "3\n",
            "2\n",
            "1\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  # regular expression patterns for code\n",
        "  pattern1 = r\"\\b\\w{6}\\b\" # word with 6 positions\n",
        "  pattern2 = r\"\\b^[a-zA-Z]{2}\\w+\" # start with 2 characters\n",
        "  pattern3 = r\"\\d{1}$\" # end with 2 numbers\n",
        "\n",
        "  matches3 = '123n'\n",
        "\n",
        "  #matches1 = re.findall(pattern1, course_code)\n",
        "  #matches2 = re.findall(pattern2, course_code)\n",
        "  matches3 = re.findall(pattern3, matches3)\n",
        "\n",
        "  print(matches3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c2Zsho_6wGc",
        "outputId": "f6156458-1907-44c7-def8-a13599ea2f2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        }
      ]
    }
  ]
}