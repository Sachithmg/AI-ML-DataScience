{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Document Segmentation\n",
        "\n",
        "This module is designed to create functions to support the segmentation process and integrate OWR models.\n",
        "\n",
        "The segmentation will be managed using the function designed in owr_segmentation.ipynb and function taken from owr_segmentation_v2.ipynb and further clean only to hold required OWR functionality"
      ],
      "metadata": {
        "id": "CI2sEfsnrLZX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2tgxr6XIm5n2",
        "outputId": "1b28cea8-8a92-403d-8626-29ac99722161"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive/\n"
          ]
        }
      ],
      "source": [
        "# do not run when we import this package as module\n",
        "#if __name__ == '__main__':\n",
        "# Connect Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#if __name__ == '__main__':\n",
        "## Load all ipynb files from Google Drive to Colab environment\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "def find_and_copy_files(src_folder, dest_folder, file_extension):\n",
        "  for foldername, subfolders, filenames in os.walk(src_folder):\n",
        "      for filename in filenames:\n",
        "          if filename.endswith(file_extension):\n",
        "              src_file = os.path.join(foldername, filename)\n",
        "              dest_file = os.path.join(dest_folder, filename)\n",
        "              try:\n",
        "                  shutil.copy2(src_file, dest_file)  # Use shutil.copy if you don't need metadata\n",
        "                  print(f\"Copied: {src_file} to {dest_file}\")\n",
        "              except Exception as e:\n",
        "                  print(f\"Error copying {src_file}: {e}\")"
      ],
      "metadata": {
        "id": "hE6iBaIgr8b5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if __name__ == '__main__':\n",
        "src_folder = '/content/gdrive/MyDrive/OWR/source'\n",
        "dest_folder = '/content'\n",
        "file_extension = '.ipynb'\n",
        "\n",
        "# Call the function to find and copy files\n",
        "find_and_copy_files(src_folder, dest_folder, file_extension)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y64C4I3ur_NL",
        "outputId": "43f3e882-603d-4b5f-afcb-72219aec9dd2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copied: /content/gdrive/MyDrive/OWR/source/input_generator/owr_input_generator.ipynb to /content/owr_input_generator.ipynb\n",
            "Copied: /content/gdrive/MyDrive/OWR/source/owr_model/owr_model_v2.ipynb to /content/owr_model_v2.ipynb\n",
            "Copied: /content/gdrive/MyDrive/OWR/source/owr_model/owr_segmentation_v3.ipynb to /content/owr_segmentation_v3.ipynb\n",
            "Copied: /content/gdrive/MyDrive/OWR/source/owr_model/preprocessing/owr_preprocess_skew_CNN_classification.ipynb to /content/owr_preprocess_skew_CNN_classification.ipynb\n",
            "Copied: /content/gdrive/MyDrive/OWR/source/owr_model/preprocessing/owr_preprocess_skew_CNN_regression.ipynb to /content/owr_preprocess_skew_CNN_regression.ipynb\n",
            "Copied: /content/gdrive/MyDrive/OWR/source/owr_model/preprocessing/owr_preprocess_skew_cv.ipynb to /content/owr_preprocess_skew_cv.ipynb\n",
            "Copied: /content/gdrive/MyDrive/OWR/source/owr_model/preprocessing/owr_preprocessing.ipynb to /content/owr_preprocessing.ipynb\n",
            "Copied: /content/gdrive/MyDrive/OWR/source/owr_model/preprocessing/owr_pre_skew_cv_base.ipynb to /content/owr_pre_skew_cv_base.ipynb\n",
            "Copied: /content/gdrive/MyDrive/OWR/source/owr_model/preprocessing/owr_preprocess_skew_tilt.ipynb to /content/owr_preprocess_skew_tilt.ipynb\n",
            "Copied: /content/gdrive/MyDrive/OWR/source/owr_model/postprocessing/owr_postprocess_module.ipynb to /content/owr_postprocess_module.ipynb\n",
            "Copied: /content/gdrive/MyDrive/OWR/source/backup/owr_segmentation_v2.ipynb to /content/owr_segmentation_v2.ipynb\n",
            "Copied: /content/gdrive/MyDrive/OWR/source/backup/CourseDescriptor.ipynb to /content/CourseDescriptor.ipynb\n",
            "Copied: /content/gdrive/MyDrive/OWR/source/mysql/owr_data_model_v1.ipynb to /content/owr_data_model_v1.ipynb\n",
            "Copied: /content/gdrive/MyDrive/OWR/source/comparison/owr_word_matching_v1.ipynb to /content/owr_word_matching_v1.ipynb\n",
            "Copied: /content/gdrive/MyDrive/OWR/source/comparison/owr_comparison_data_module_v1.ipynb to /content/owr_comparison_data_module_v1.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#if __name__ == '__main__':\n",
        "from IPython.display import clear_output as cls\n",
        "!pip install import_ipynb\n",
        "import import_ipynb\n",
        "\n",
        "cls()"
      ],
      "metadata": {
        "id": "gcNzgUPMsB63"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#if __name__ == '__main__':\n",
        "# Import Colab Models\n",
        "import owr_preprocessing as BPP\n",
        "import owr_model_v2 as WM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zqd8_N55sFlq",
        "outputId": "feda499f-1afb-469f-a1b0-09ead9a6eaa2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "importing Jupyter notebook from owr_preprocessing.ipynb\n",
            "importing Jupyter notebook from owr_model_v2.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Libraries\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL.Image as Image\n",
        "import numpy as np\n",
        "import math\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from IPython.display import clear_output as cls\n",
        "\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "M2bF36IcscOz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Global Parameters\n",
        "CharHeight4Line = 6\n",
        "CharWidth4Line = 185\n",
        "\n",
        "CharHeight = 6\n",
        "CharWidth = 5"
      ],
      "metadata": {
        "id": "dqPF71fgsfiE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imgZoom(img):\n",
        "  # Get the current size of the image\n",
        "  current_height, current_width, _ = img.shape\n",
        "\n",
        "  # Calculate the new size (3/2 times the current size)\n",
        "  new_height = int(current_height * 3 / 2)\n",
        "  new_width = int(current_width * 3 / 2)\n",
        "\n",
        "  # Resize the image\n",
        "  return cv2.resize(img, (new_width, new_height))"
      ],
      "metadata": {
        "id": "uyImLwzusi-X"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The prerequisite for the function is a Binary image.\n",
        "def getContours(img):\n",
        "\n",
        "  # Define Kernel for Morphological Operations\n",
        "\n",
        "  # Image width\n",
        "  kernel_length = np.array(img).shape[1]//80\n",
        "\n",
        "  # A verticle kernel of (1 x kernel_length)\n",
        "  verticle_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1,kernel_length))\n",
        "\n",
        "  # A horizontal kernel of (kernel_length x 1)\n",
        "  hori_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_length,1))\n",
        "\n",
        "  # A kernel of (3 x 3) ones\n",
        "  kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))\n",
        "\n",
        "\n",
        "  # Morphological operation to detect vertical lines from an image\n",
        "  img_temp1 = cv2.erode(img, verticle_kernel, iterations=3)\n",
        "  vertical_lines_img = cv2.dilate(img_temp1, verticle_kernel, iterations=3)\n",
        "\n",
        "  # Morphological operation to detect horizontal lines from an image\n",
        "  img_temp2 = cv2.erode(img, hori_kernel, iterations=3)\n",
        "  horizontal_lines_img = cv2.dilate(img_temp2, hori_kernel, iterations=3)\n",
        "\n",
        "  # Weighting parameters, this will decide the quantity of an image to be added to make a new image.\n",
        "  alpha = 0.5\n",
        "  beta = 1.0 - alpha\n",
        "\n",
        "\n",
        "  # This function helps to add two image with specific weight parameter to get a third image as summation of two image.\n",
        "  img_final_bin = cv2.addWeighted(vertical_lines_img, alpha, horizontal_lines_img, beta, 0.0)\n",
        "  img_final_bin = cv2.erode(~img_final_bin, kernel, iterations=2)\n",
        "\n",
        "  (thresh, img_final_bin) = cv2.threshold(img_final_bin, 128,255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
        "\n",
        "  # Find contours for image, which will detect all the boxes\n",
        "  contours, hierarchy = cv2.findContours(img_final_bin, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "  '''\n",
        "  0 : Star [1,-1,-1,-1]\n",
        "  … Next — Outer Square (1)\n",
        "  … Previous — No Contour(-1)\n",
        "  … Child — No Child (-1)\n",
        "  … Parent — No Parent (-1)\n",
        "\n",
        "  '''\n",
        "\n",
        "  # Initialize lists to store outer rectangles and their child contours\n",
        "  outer_rectangles = []\n",
        "  child_contours = []\n",
        "\n",
        "  # Iterate through the hierarchy to find outer rectangles and their children\n",
        "  for i in range(len(contours)):\n",
        "\n",
        "      if hierarchy[0][i][3] == 0:  # Check if the contour has no parent (i.e., it's an outer contour)\n",
        "          # Calculate the bounding rectangle of the outer contour\n",
        "          x, y, w, h = cv2.boundingRect(contours[i])\n",
        "          outer_rectangles.append((x, y, x + w, y + h))\n",
        "\n",
        "          # Find child contours of the outer contour\n",
        "          children = []\n",
        "          for j in range(len(contours)):\n",
        "              if hierarchy[0][j][3] == i:  # Check if contour j is a child of contour i\n",
        "                  child_contour = contours[j]\n",
        "                  x, y, w, h = cv2.boundingRect(child_contour)\n",
        "                  children.append((x, y, x + w, y + h))\n",
        "          child_contours.append(children)\n",
        "\n",
        "  # Sort the outer rectangles based on their top-left coordinates (y, x)\n",
        "  outer_rectangles = sorted(outer_rectangles, key=lambda rect: (rect[1], rect[0]))\n",
        "\n",
        "  # Sort the child contours based on their top-left coordinates (y, x)\n",
        "  for i in range(len(child_contours)):\n",
        "    child_contours[i] = sorted(child_contours[i], key=lambda rect: (rect[1], rect[0]))\n",
        "\n",
        "  child_min_y = []\n",
        "  for i in range(len(child_contours)):\n",
        "    y_min = np.array(img).shape[0]\n",
        "    for j in range(len(child_contours[i])):\n",
        "      if y_min > child_contours[i][j][1]:\n",
        "        y_min = child_contours[i][j][1]\n",
        "\n",
        "    child_min_y.append((y_min, i))\n",
        "  child_min_y = np.array(child_min_y)\n",
        "  if child_min_y.ndim != 1:\n",
        "    sorted_array = child_min_y[child_min_y[:, 0].argsort()]\n",
        "  else: sorted_array = child_min_y\n",
        "\n",
        "\n",
        "  tempChild = []\n",
        "  for i in range(len(sorted_array)):\n",
        "    tempChild.append(child_contours[sorted_array[i][1]])\n",
        "\n",
        "  child_contours = tempChild\n",
        "\n",
        "  # Return the contours\n",
        "  return outer_rectangles, child_contours"
      ],
      "metadata": {
        "id": "xVtRWD9Dsmxy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getBinarized(OrgImg, Zoom=True):\n",
        "\n",
        "  if Zoom:\n",
        "    OrgImg = imgZoom(OrgImg)\n",
        "\n",
        "  # Convert image to Grayscale\n",
        "  GrayImg = BPP.set_grayscale(OrgImg)\n",
        "\n",
        "  # Binarization\n",
        "  BinaryImg = BPP.set_Adaptive_Binarization(GrayImg)\n",
        "\n",
        "  return BinaryImg"
      ],
      "metadata": {
        "id": "VVv6LJ_Ks_mV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getTableImg(orgImg, outer_rectangles, extract=-1):\n",
        "  ''' Retuen Table from Image\n",
        "    As per the CD template there are two tables\n",
        "    1. Code and Course Title\n",
        "    2. Assessments\n",
        "    Input Parameter\n",
        "    Extract:\n",
        "      1 - Code and Course Title\n",
        "      2 - Assessments\n",
        "      -1 - Without Code, Course Title and Assessments\n",
        "  '''\n",
        "  orgImg = orgImg.copy()\n",
        "\n",
        "  if extract == 1 and len(outer_rectangles) > 0:\n",
        "    x1, y1, x2,y2 = outer_rectangles[0]\n",
        "    return orgImg[y1:y2, x1:x2]\n",
        "  elif extract == 2 and len(outer_rectangles) > 1:\n",
        "    x1, y1, x2,y2 = outer_rectangles[1]\n",
        "    return orgImg[y1:y2, x1:x2]\n",
        "  else:\n",
        "    for rect in outer_rectangles:\n",
        "      x1, y1, x2, y2 = rect\n",
        "      cv2.rectangle(orgImg, (x1, y1), (x2, y2), 0, thickness=cv2.FILLED)\n",
        "    return orgImg\n",
        "\n"
      ],
      "metadata": {
        "id": "QiQFbo4PtDkj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imgCourseCode(img, outer_rectangles, child_contours):\n",
        "  try:\n",
        "    out_x1, out_y1, out_x2, out_y2 = outer_rectangles[0]\n",
        "    child_x1, child_y1, child_x2, child_y2 = child_contours[0][0]\n",
        "\n",
        "    x1 = child_x1 - out_x1\n",
        "    y1 = child_y1 - out_y1\n",
        "    x2 = child_x2 - out_x1\n",
        "    y2 = child_y2 - out_y1\n",
        "\n",
        "    img = img[y1:y2, x1:x2]\n",
        "  except: img = img\n",
        "\n",
        "  return img"
      ],
      "metadata": {
        "id": "q8nNSts8tNTH"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imgCourseTitle(img, outer_rectangles, child_contours):\n",
        "  try:\n",
        "    out_x1, out_y1, out_x2, out_y2 = outer_rectangles[0]\n",
        "    child_x1, child_y1, child_x2, child_y2 = child_contours[0][1]\n",
        "\n",
        "    x1 = child_x1 - out_x1\n",
        "    y1 = child_y1 - out_y1\n",
        "    x2 = child_x2 - out_x1\n",
        "    y2 = child_y2 - out_y1\n",
        "\n",
        "    img = img[y1:y2, x1:x2]\n",
        "  except: img = img\n",
        "\n",
        "  return img"
      ],
      "metadata": {
        "id": "m1Yn68h8tRLV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imgAssessments(img, outer_rectangles, child_contours, row):\n",
        "  if row == 0:\n",
        "    index = 0\n",
        "  else:\n",
        "    index = 0\n",
        "    for j in range(row):\n",
        "      index += 3\n",
        "\n",
        "  try:\n",
        "\n",
        "    out_x1, out_y1, out_x2, out_y2 = outer_rectangles[1]\n",
        "\n",
        "    for i in range(3):\n",
        "      child_x1, child_y1, child_x2, child_y2 = child_contours[1][index + i]\n",
        "\n",
        "      x1 = child_x1 - out_x1\n",
        "      y1 = child_y1 - out_y1\n",
        "      x2 = child_x2 - out_x1\n",
        "      y2 = child_y2 - out_y1\n",
        "\n",
        "      if i == 0:\n",
        "        method = img[y1:y2, x1:x2]\n",
        "      elif i == 1:\n",
        "        weight = img[y1:y2, x1:x2]\n",
        "      else:\n",
        "        learning = img[y1:y2, x1:x2]\n",
        "  except:\n",
        "      if i == 0:\n",
        "        method = img\n",
        "      elif i == 1:\n",
        "        weight = img\n",
        "      else:\n",
        "        learning = img\n",
        "\n",
        "  return method, weight, learning"
      ],
      "metadata": {
        "id": "PJR_TuGHa9oe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getLines(img):\n",
        "  kernel = np.ones((CharHeight4Line, CharWidth4Line), np.uint8)\n",
        "  try:\n",
        "    dilated = cv2.dilate(img, kernel, iterations=1)\n",
        "\n",
        "    #cv2_imshow(dilated)\n",
        "\n",
        "    (contours, heirarchy) = cv2.findContours(dilated.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    sorted_contours_lines = sorted(contours, key = lambda ctr : cv2.boundingRect(ctr)[1]) # (x, y, w, h)\n",
        "\n",
        "    line_contours = []\n",
        "    for line in sorted_contours_lines:\n",
        "      x, y, w, h = cv2.boundingRect(line)\n",
        "      line_contours.append((x, y, x + w, y + h))\n",
        "\n",
        "  except: line_contours = []\n",
        "\n",
        "  return line_contours"
      ],
      "metadata": {
        "id": "CqAD7n_dbC3H"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getWords(img, lines, index):\n",
        "  words_list = []\n",
        "  kernel = np.ones((CharHeight,CharWidth), np.uint8)\n",
        "  try:\n",
        "    x = lines[index][0]\n",
        "    y = lines[index][1]\n",
        "    x_e = lines[index][2]\n",
        "    y_e = lines[index][3]\n",
        "\n",
        "\n",
        "    #print(x, y, x_e, y_e)\n",
        "    img = img[y:y_e, x:x_e]\n",
        "    #cv2_imshow(img)\n",
        "    #print(img.shape)\n",
        "\n",
        "    dilated = cv2.dilate(img, kernel, iterations = 1)\n",
        "\n",
        "    # draw contours on each word\n",
        "    (cnt, heirarchy) = cv2.findContours(dilated.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "    sorted_contour_words = sorted(cnt, key=lambda cntr : cv2.boundingRect(cntr)[0])\n",
        "\n",
        "    for word in sorted_contour_words:\n",
        "\n",
        "      x2, y2, w2, h2 = cv2.boundingRect(word)\n",
        "      words_list.append([x+x2, y+y2, x+x2+w2, y+y2+h2])\n",
        "\n",
        "    # Remove overlapping rectangles\n",
        "    non_overlapping_coordinates = remove_overlapping(words_list)\n",
        "  except: non_overlapping_coordinates = words_list\n",
        "  return non_overlapping_coordinates"
      ],
      "metadata": {
        "id": "c1RG5gY6btV3"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_area(coord):\n",
        "    # Calculate the area of a rectangle defined by [x, y, w, h]\n",
        "    return (coord[2] - coord[0]) * (coord[3] - coord[1])\n",
        "\n",
        "def is_overlapping(coord1, coord2):\n",
        "    buffer = 10\n",
        "    # Check if two rectangles defined by [x, y, w, h] are overlapping\n",
        "    x1, y1, x12, y12 = coord1\n",
        "    x2, y2, x22, y22 = coord2\n",
        "    #return (x1 < x2 + w2 and x1 + w1 > x2 and y1 < y2 + h2 and y1 + h1 > y2)\n",
        "    return ((x1 - buffer <= x2 <= x12 + buffer and x1 - buffer <= x22 <= x12 + buffer\n",
        "             and y1 - buffer <= y2 <= y12 + buffer and y1 - buffer <= y22 <= y12 +buffer)\n",
        "          or (x2 - buffer <= x1 <= x22 + buffer and x2 - buffer <= x12 <= x22 + buffer\n",
        "              and y2 - buffer <= y1 <= y22 + buffer and y2 - buffer <= y12 <= y22 + buffer))\n",
        "\n",
        "def remove_overlapping(rectangles):\n",
        "    # Sort the rectangles by area (largest first)\n",
        "    rectangles.sort(key=calculate_area, reverse=True)\n",
        "\n",
        "    # Initialize a list to store non-overlapping rectangles\n",
        "    non_overlapping_rectangles = []\n",
        "\n",
        "    for rect in rectangles:\n",
        "        if all(not is_overlapping(rect, existing_rect) for existing_rect in non_overlapping_rectangles):\n",
        "            non_overlapping_rectangles.append(rect)\n",
        "\n",
        "    non_overlapping_rectangles = sorted(non_overlapping_rectangles, key=lambda rect : rect[0])\n",
        "    # Sort the outer rectangles based on their top-left coordinates (y, x)\n",
        "    #outer_rectangles = sorted(outer_rectangles, key=lambda rect: (rect[1], rect[0]))\n",
        "\n",
        "    return non_overlapping_rectangles\n",
        "\n"
      ],
      "metadata": {
        "id": "vW3jeLLIbwzL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Word Prediction Model\n",
        "def load_word_prediction_model(model_path):\n",
        "\n",
        "    model = WM.Image_text_recogniser_model_1('predict')\n",
        "\n",
        "    model.load_weights(model_path)\n",
        "\n",
        "    #Letters present in the Label Text\n",
        "    letters= '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "\n",
        "    n_letters = len(letters)\n",
        "    return model, letters, n_letters"
      ],
      "metadata": {
        "id": "dKe7fhCAd2Yo"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def findWord(model, img):\n",
        "\n",
        "  img = cv2.resize(img,(170,32))\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "  img = img[:,:,1]\n",
        "  img = img.T\n",
        "  img = np.expand_dims(img, axis=-1)\n",
        "  img = np.expand_dims(img, axis=0)\n",
        "  img = img/255\n",
        "\n",
        "  model_output = model.predict(img, verbose=None)\n",
        "  predicted_output = WM.decode_label(model_output)\n",
        "\n",
        "  return predicted_output"
      ],
      "metadata": {
        "id": "QdpEqj3qd9ZF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_Words(img, Model_Word, funWord, WordClasses):\n",
        "  wordList = []\n",
        "\n",
        "  Lines = getLines(img)\n",
        "\n",
        "  for i in range(len(Lines)):\n",
        "    words = getWords(img, Lines, i)\n",
        "\n",
        "    result_word = ''\n",
        "    for word in words:\n",
        "      imgWord = img[word[1]:word[3], word[0]:word[2]]\n",
        "\n",
        "      # Predic Word\n",
        "      word_image = cv2.bitwise_not(imgWord)\n",
        "      predict_word = funWord(Model_Word, word_image)\n",
        "      #wordList.append(predict_word)\n",
        "\n",
        "      if len(result_word) > 0:\n",
        "        result_word = result_word + ' ' + predict_word\n",
        "      else: result_word =  predict_word\n",
        "\n",
        "    wordList.append(result_word)\n",
        "\n",
        "  return wordList"
      ],
      "metadata": {
        "id": "W1bK1v9OeEAc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_courseCode(img, outer_rectangles, child_contours, \\\n",
        "                   Model_Word, funWord, WordClasses ):\n",
        "\n",
        "  # Get Course Code\n",
        "  img = imgCourseCode(img, outer_rectangles, child_contours)\n",
        "\n",
        "  wordList = get_Words(img, Model_Word, funWord, WordClasses)\n",
        "\n",
        "  for i in range(len(wordList)):\n",
        "    wordList[i] = wordList[i].replace(' ', '')\n",
        "\n",
        "  courseCode = ''.join(wordList)\n",
        "\n",
        "  courseCode = courseCode[0:2] + courseCode[2:].replace('S','5')\n",
        "  courseCode = courseCode[0:2] + courseCode[2:].replace('A','4')\n",
        "  courseCode = courseCode[0:2] + courseCode[2:].replace('L','1')\n",
        "  courseCode = courseCode[0:2] + courseCode[2:].replace('O','0')\n",
        "  courseCode = courseCode[0:2] + courseCode[2:].replace('I','1')\n",
        "  courseCode = courseCode[0:2] + courseCode[2:].replace('Z','2')\n",
        "  courseCode = courseCode[0:2] + courseCode[2:].replace('E','3')\n",
        "  courseCode = courseCode[0:2] + courseCode[2:].replace('B','3')\n",
        "\n",
        "  return courseCode\n",
        "\n",
        "def get_courseTitle(img, outer_rectangles, child_contours, \\\n",
        "                   Model_Word, funWord, WordClasses ):\n",
        "\n",
        "  # Get Course Title\n",
        "  img = imgCourseTitle(img, outer_rectangles, child_contours)\n",
        "\n",
        "  wordList = get_Words(img, Model_Word, funWord, WordClasses )\n",
        "\n",
        "  courseTitle = ' '.join(wordList)\n",
        "\n",
        "  return courseTitle\n",
        "\n",
        "\n",
        "def get_courseAssessment(img, outer_rectangles, child_contours, \\\n",
        "                         Model_Word, funWord, WordClasses ):\n",
        "\n",
        "  if len(child_contours) > 1:\n",
        "    num_of_rows = len(child_contours[1]) // 3\n",
        "  else: num_of_rows = 0\n",
        "\n",
        "  word_method = []\n",
        "  word_weight = []\n",
        "  word_learning = []\n",
        "\n",
        "\n",
        "  # Get Assessment\n",
        "  for row in range(num_of_rows):\n",
        "    imgChild1, imgChild2, imgChild3 = imgAssessments(img, outer_rectangles, child_contours, row)\n",
        "\n",
        "    wordMethod = get_Words(imgChild1, Model_Word, funWord, WordClasses)\n",
        "    wordWeight = get_Words(imgChild2, Model_Word, funWord, WordClasses)\n",
        "    wordLearning = get_Words(imgChild3, Model_Word, funWord, WordClasses)\n",
        "\n",
        "    word_method.append(wordMethod)\n",
        "    word_weight.append(wordWeight)\n",
        "    word_learning.append(wordLearning)\n",
        "\n",
        "\n",
        "  return (word_method, word_weight, word_learning)\n",
        "\n",
        "\n",
        "def get_Doc(img, Model_Word, funWord, WordClasses):\n",
        "\n",
        "  return get_Words(img, Model_Word, funWord, WordClasses)"
      ],
      "metadata": {
        "id": "907oKPy-eVMD"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}